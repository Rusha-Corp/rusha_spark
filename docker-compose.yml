services:
  spark-thrift-server:
    build: 
      context: .
      dockerfile: Dockerfile
    hostname: spark-thrift-server
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN}
      - AWS_REGION=${AWS_DEFAULT_REGION}
      - SPARK_WAREHOUSE_DIR=${WAREHOUSE}
      - METASTORE_URIS=${METASTORE_URIS}
      - SPARK_LOG_DIR=/tmp/spark-events
      - SPARK_DRIVER_HOST=spark-thrift-server
      - SPARK_EXECUTOR_CORES=8
      - SPARK_EXECUTOR_MEMORY=32G
      - SPARK_DRIVER_MEMORY=32G
      - SPARK_DRIVER_CORES=8
      - HADOOP_AWS_CREDENTIAL_PROVIDER_CLASS=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    volumes:
      - ./tmp:/tmp
    networks:
      - spark-container-network
    restart: always
    entrypoint: ["/bin/bash", "-c", "/start_thrift_server.sh"]
    deploy:
      resources:
        limits:
          cpus: "8"
          memory: 48G
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 10000"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    profiles:
      - common
      - spark-node

  hue:
    image: gethue/hue:latest
    hostname: hue
    container_name: hue
    depends_on:
      - spark-thrift-server
    volumes:
      - ./conf:/usr/share/hue/desktop/conf
    networks:
      - spark-container-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 4G
    profiles:
      - common

  ml:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN}
      - AWS_REGION=${AWS_DEFAULT_REGION}
      - MLFLOW_TRACKING_USERNAME=${MLFLOW_TRACKING_USERNAME}
      - MLFLOW_TRACKING_PASSWORD=${MLFLOW_TRACKING_PASSWORD}
    command: mlflow server --backend-store-uri postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/mlflow --default-artifact-root ${ARTIFACTS_ROOT} --host 0.0.0.0 --port 5000 #--app-name basic-auth
    volumes:
      - ./tmp:/tmp
      - ./mlflow:/mlflow
    networks:
      - spark-container-network
    restart: always
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 4G
    profiles:
      - common

  iceberg-rest:
    image: apache/iceberg-rest-fixture
    container_name: iceberg-rest
    networks:
      - spark-container-network
    restart: always
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_DEFAULT_REGION}
      - CATALOG_WAREHOUSE=${WAREHOUSE}/iceberg_catalog
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=s3.${AWS_DEFAULT_REGION}.amazonaws.com
      - CATALOG_JDBC__IMPL=org.postgresql.Driver
      - CATALOG_JDBC__URL=jdbc:postgresql://postgres:5432/postgres
      - CATALOG_JDBC__USER=postgres
      - CATALOG_JDBC__PASSWORD=password
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 4G
    profiles:
      - common

  ingress:
    image: nginx:latest
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./certs:/etc/letsencrypt
    networks:
      - spark-container-network
    restart: always
    depends_on:
      - spark-thrift-server
      - hue
      - ml
      - iceberg-rest
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 4G
    profiles:
      - common

networks:
  spark-container-network:
    external: true
